{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = pd.read_csv('../data/train_cleaned.csv', index_col='Id')\n",
    "test_cleaned = pd.read_csv('../data/test_cleaned.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "\n",
    "X_train = train_cleaned.drop(['SalePrice', 'PID'], axis=1).copy()\n",
    "y_train = train_cleaned[['SalePrice']].copy()\n",
    "\n",
    "# Test data\n",
    "\n",
    "X_test = test_cleaned.drop(['PID'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MS SubClass', 'MS Zoning', 'Lot Frontage', 'Lot Area', 'Street',\n",
       "       'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config',\n",
       "       'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type',\n",
       "       'House Style', 'Overall Qual', 'Overall Cond', 'Year Built',\n",
       "       'Year Remod/Add', 'Roof Style', 'Roof Matl', 'Exterior 1st',\n",
       "       'Exterior 2nd', 'Mas Vnr Type', 'Mas Vnr Area', 'Exter Qual',\n",
       "       'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure',\n",
       "       'BsmtFin Type 1', 'BsmtFin SF 1', 'BsmtFin Type 2', 'BsmtFin SF 2',\n",
       "       'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air',\n",
       "       'Electrical', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF',\n",
       "       'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath',\n",
       "       'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual',\n",
       "       'TotRms AbvGrd', 'Functional', 'Fireplaces', 'Fireplace Qu',\n",
       "       'Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Cars',\n",
       "       'Garage Area', 'Garage Qual', 'Garage Cond', 'Paved Drive',\n",
       "       'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
       "       'Screen Porch', 'Pool Area', 'Pool QC', 'Fence', 'Misc Feature',\n",
       "       'Misc Val', 'Mo Sold', 'Yr Sold', 'Sale Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MS SubClass', 'MS Zoning', 'Lot Frontage', 'Lot Area', 'Street',\n",
       "       'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config',\n",
       "       'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type',\n",
       "       'House Style', 'Overall Qual', 'Overall Cond', 'Year Built',\n",
       "       'Year Remod/Add', 'Roof Style', 'Roof Matl', 'Exterior 1st',\n",
       "       'Exterior 2nd', 'Mas Vnr Type', 'Mas Vnr Area', 'Exter Qual',\n",
       "       'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure',\n",
       "       'BsmtFin Type 1', 'BsmtFin SF 1', 'BsmtFin Type 2', 'BsmtFin SF 2',\n",
       "       'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air',\n",
       "       'Electrical', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF',\n",
       "       'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath',\n",
       "       'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual',\n",
       "       'TotRms AbvGrd', 'Functional', 'Fireplaces', 'Fireplace Qu',\n",
       "       'Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Cars',\n",
       "       'Garage Area', 'Garage Qual', 'Garage Cond', 'Paved Drive',\n",
       "       'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
       "       'Screen Porch', 'Pool Area', 'Pool QC', 'Fence', 'Misc Feature',\n",
       "       'Misc Val', 'Mo Sold', 'Yr Sold', 'Sale Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = ['PID', 'MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config',\n",
    "                    'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style',\n",
    "                    'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating',\n",
    "                    'Central Air', 'Garage Type', 'Misc Feature', 'Sale Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all nominal features except PID\n",
    "reduced_nominal_features = nominal_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get dummies of train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=reduced_nominal_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Get dummies of test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns=reduced_nominal_features, drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ensure that the number of columns in the train and test datasets are identical and in the same order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_unequal_train_test_columns(X_train, X_test):\n",
    "    columns_not_in_test = list(set(X_train.columns).difference(set(X_test.columns)))\n",
    "    for col in columns_not_in_test:\n",
    "        X_test[col] = 0\n",
    "        \n",
    "    columns_not_in_train = list(set(X_test.columns).difference(set(X_train.columns)))\n",
    "    X_test.drop(columns_not_in_train, axis=1, inplace=True)\n",
    "    return X_train[sorted(X_train.columns)], X_test[sorted(X_test.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = handle_unequal_train_test_columns(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(X_test.columns, X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adj(y_true, y_preds, p):\n",
    "    n = len(y_true)\n",
    "    y_mean = np.mean(y_true)\n",
    "    numerator = np.sum(np.square(y_true - y_preds)) / (n - p - 1)\n",
    "    denominator = np.sum(np.square(y_true - y_mean)) / (n - 1)\n",
    "    return (1 - (numerator / denominator)).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_metrics(y_true, y_pred, p):\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    msle = metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    mae = metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    r2a = r2_adj(y_true, y_pred, p)\n",
    "    \n",
    "    print('Mean squared error      = ', mse)\n",
    "    print('Root mean squared error = ', rmse)\n",
    "    print('Mean squared log error  = ', msle)\n",
    "    print('Median absolute error   = ', mae)\n",
    "    print('R^2                     = ', r2)\n",
    "    print('Adjusted R^2            = ', r2a)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'msle': msle,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'r2_adjusted': r2a\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_metrics = get_regression_metrics(y_train, y_train_pred, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regression_metrics['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(linreg, X_train, y_train, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = [i[0] for i in y_test_pred.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_get_submissions_file(X_test_indices, y_test_pred, file_name):\n",
    "    submissions = pd.DataFrame({'Id': X_test_indices, 'SalePrice': y_test_pred})\n",
    "    submissions.set_index('Id', inplace=True)\n",
    "    submissions.sort_index(inplace=True)\n",
    "    submissions.to_csv('../data/{}.csv'.format(file_name))\n",
    "    \n",
    "    return submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = make_and_get_submissions_file(X_test_indices, y_test_pred, 'submissions_baseline_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "\n",
    "X_train = train_cleaned.drop(['SalePrice', 'PID'], axis=1).copy()\n",
    "y_train = train_cleaned[['SalePrice']].copy()\n",
    "\n",
    "# Test data\n",
    "X_test = test_cleaned.drop(['PID'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = ['PID', 'MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config',\n",
    "                    'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style',\n",
    "                    'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating',\n",
    "                    'Central Air', 'Garage Type', 'Misc Feature', 'Sale Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all nominal features except PID\n",
    "reduced_nominal_features = nominal_features[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get dummies for ordinal features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=reduced_nominal_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns=reduced_nominal_features, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = handle_unequal_train_test_columns(X_train, X_test)\n",
    "X_train_columns = X_train.columns\n",
    "X_test_columns = X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization of features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Regression with All Features** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "optimal_lasso = LassoCV(n_alphas=500, cv=10) # uses 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting and Evaluation\n",
    "optimal_lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, X_train, y_train, cv=10)\n",
    "lasso_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-cross_val_score(lasso, X_train, y_train, cv=10, scoring='neg_root_mean_squared_error')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = make_and_get_submissions_file(X_test_indices, y_test_pred, 'submissions_lasso_regression_all_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.stem(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lasso.coef_ != 0).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_columns[(lasso.coef_ != 0).nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_[(lasso.coef_ != 0).nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross Validation\n",
    "# ridge = RidgeCV(alphas=np.logspace(0, 5, 200))\n",
    "# ridge_scores = cross_val_score(ridge, X_train, y_train, cv=10)\n",
    "# ridge_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "optimal_ridge = RidgeCV(alphas=np.logspace(0, 5, 200), cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting and Evaluation\n",
    "optimal_ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge = Ridge(alpha=optimal_ridge.alpha_)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, X_train, y_train, cv=10)\n",
    "ridge_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-cross_val_score(ridge, X_train, y_train, cv=10, scoring='neg_root_mean_squared_error')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_test_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = make_and_get_submissions_file(X_test_indices, y_test_pred, 'submissions_ridge_regression_all_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(nominal_features).difference(set(train_cleaned.corr().columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(nominal_features).difference(set(train_cleaned.corr().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned[sorted(nominal_features)].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(train_cleaned.corr(), annot=False, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
